{
    "contents" : "---\ntitle: \"Analyzing Inherence Heuristic Cognitive Load Data\"\nauthor: \"Erika Salomon\"\ndate: \"October 1, 2015\"\noutput: \n  pdf_document:\n    fig_caption: yes\n---\n\n```{r, include=FALSE}\n## Load Packages\nlibrary(scrapeR)\nlibrary(XML)\nlibrary(psych)\nlibrary(ggplot2)\nlibrary(GGally)\nlibrary(plyr)\nlibrary(rjson)\n```\n\n## Summary\n\nThis file reports data manipulations and analyses performed on an experiment studying plausibility ratings for explanations. The explanations vary in whether they are inherent (i.e., refer only to the entities being explained) or extrinsic (i.e., refer to things, events, processes, etc. beyond the entities being explained). Each participant only rated one kind of explanation. In addition, participants completed this task either under high cognitive load (i.e., being asked to remember a 10 digit number for the duration of the task) or under low cognitive load (i.e., no memory task). \n\n## Load the raw data and combine data sets\n\nThe data were collected from three different online surveys implemented in Qualtrics. First, the files must be loaded and combined into a single raw data matrix.\n\nThe first row of each file contains most of the variable names. The second row contains some further variable names and the question wording. Rows three and beyond contain participant data. So, for each file, we will first load in the two sets of variable names and combine them. Then, we will load in the data.\n\n```{r, cache=FALSE}\n# File 1\nname1.1 <- names(read.csv(\"IH__Cognitive_Load__IntrinsicExtrinsic_Between_Subjects.csv\",\n                          nrow = 1))\nname1.2 <- names(read.csv(\"IH__Cognitive_Load__IntrinsicExtrinsic_Between_Subjects.csv\",\n                          nrow = 1, skip = 1))\nnames1 <- c(name1.2[1:13], name1.1[14:(length(name1.1))])\nraw1 <- read.csv(\"IH__Cognitive_Load__IntrinsicExtrinsic_Between_Subjects.csv\",\n                 header = FALSE, skip = 2, col.names = names1, \n                 stringsAsFactors = FALSE)\n\n# File 2\nname2.1 <- names(read.csv(\"IH_Demo_Study_7__Cog_Load__V_5_Rate_Intr_Only.csv\",\n                          nrow = 1))\nname2.2 <- names(read.csv(\"IH_Demo_Study_7__Cog_Load__V_5_Rate_Intr_Only.csv\",\n                          nrow = 1, skip = 1))\nnames2 <- c(name2.2[1:13], name2.1[14:(length(name2.1))])\nraw2 <- read.csv(\"IH_Demo_Study_7__Cog_Load__V_5_Rate_Intr_Only.csv\",\n                 header = FALSE, skip = 2, col.names = names2, \n                 stringsAsFactors = FALSE)\n\n# File 3\nname3.1 <- names(read.csv(\"IH_Demo_Study_8__Cog_Load__V_6_Rate_Extr_Only.csv\",\n                          nrow = 1))\nname3.2 <- names(read.csv(\"IH_Demo_Study_8__Cog_Load__V_6_Rate_Extr_Only.csv\",\n                          nrow = 1, skip = 1))\nnames3 <- c(name3.2[1:13], name3.1[14:(length(name3.1))])\nraw3 <- read.csv(\"IH_Demo_Study_8__Cog_Load__V_6_Rate_Extr_Only.csv\",\n                 header = FALSE, skip = 2, col.names = names3, \n                 stringsAsFactors = FALSE)\n```\n\nCondition wasn't recorded consistently in raw2, but it can be recovered because whether the cognitive load instructions were displayed or not WAS recorded.\n\n```{r}\nraw2$Cond[is.na(raw2$CLInstrux)] <- 1\nraw2$Cond[raw2$CLInstrux == 1] <- 2\n```\n\nVariable names differ across the data sets, so make them consistent.\n\n```{r}\n# File 1\nnames(raw1) <- c(\"ResponseID\", \"ResponseSet\", \"Name\", \"ExternalDataReference\",\n                 \"EmailAddress\", \"IPAddress\", \"Status\", \"StartDate\", \"EndDate\",\n                 \"Finished\", \"Plausibility.sum\", \"Plausibility.weightedAvg\",\n                 \"Plausibility.weightedStdDev\", \"Country\", \"Inherent\",\n                 \"OrderCon\", \"Cond\", \"NaAssign2\", \"NaAssign1\", \"CLAssign2\",\n                 \"CLAssign1\", \"CLInstrux\", \"Memorize\", \"InExIntro\", \"CerImIn\",\n                 \"CerPlIn\", \"CerImEx\", \"CerPlEx\", \"CerTime_1\", \"CerTime_2\",\n                 \"CerTime_3\", \"CerTime_4\", \"DiaImIn\", \"DiaPlIn\", \"DiaImEx\",\n                 \"DiaPlEx\", \"DiaTim_1\", \"DiaTim_2\", \"DiaTim_3\", \"DiaTim_4\",\n                 \"PinImIn\", \"PinPlIn\", \"PinImEx\", \"PinPlEx\", \"PinTime_1\",\n                 \"PinTime_2\", \"PinTime_3\", \"PinTime_4\", \"WeeImIn\", \"WeePlIn\",\n                 \"WeeImEx\", \"WeePlEx\", \"WeeTime_1\", \"WeeTime_2\", \"WeeTime_3\",\n                 \"WeeTime_4\", \"TirImIn\", \"TirPlIn\", \"TirImEx\", \"TirPlEx\",\n                 \"TirTime_1\", \"TirTime_2\", \"TirTime_3\", \"TirTime_4\", \"WhiImIn\",\n                 \"WhiPlIn\", \"WhiImEx\", \"WhiPlEx\", \"WhiTime_1\", \"WhiTime_2\",\n                 \"WhiTime_3\", \"WhiTime_4\", \"BlaImIn\", \"BlaPlIn\", \"BlaImEx\",\n                 \"BlaPlEx\", \"BlaTime_1\", \"BlaTime_2\", \"BlaTime_3\", \"BlaTime_4\",\n                 \"OJImIn\", \"OJPlIn\", \"OJImEx\", \"OJPlEx\", \"OJTime_1\", \"OJTime_2\",\n                 \"OJTime_3\", \"OJTime_4\", \"NumberIntr\", \"Number\", \"Familiarity\",\n                 \"DemoIntro\", \"DemoGender\", \"DOB\", \"Age\", \"DemoEducat\",\n                 \"Income\", \"Religion\", \"Race\", \"DebriefInt\", \"OddConfusi\",\n                 \"ThinkStudy\", \"MoreEye\", \"ThoughtsCo\", \"Debrief\",\n                 \"LocationLatitude\", \"LocationLongitude\", \"LocationAccuracy\",\n                 \"X\")\n\n# File 2\nnames(raw2) <- c(\"ResponseID\", \"ResponseSet\", \"Name\", \"ExternalDataReference\",\n                 \"EmailAddress\", \"IPAddress\", \"Status\", \"StartDate\", \"EndDate\",\n                 \"Finished\", \"Intrinsic.sum\", \"Intrinsic.weightedAvg\",\n                 \"Intrinsic.weightedStdDev\", \"OrderCon\", \"Cond\", \"Part\",\n                 \"NaAssign2\", \"NaAssign1\", \"CLAssign2\", \"CLAssign1\",\n                 \"CLInstrux\", \"Memorize\", \"InExIntro\", \"CerImIn\", \"CerPlIn\",\n                 \"CerTime_1\", \"CerTime_2\", \"CerTime_3\", \"CerTime_4\", \"DiaImIn\",\n                 \"DiaPlIn\", \"DiaTime_1\", \"DiaTime_2\", \"DiaTime_3\", \"DiaTime_4\",\n                 \"PinImIn\", \"PinPlIn\", \"PinTime_1\", \"PinTime_2\", \"PinTime_3\",\n                 \"PinTime_4\", \"WeeImIn\", \"WeePlIn\", \"WeeTime_1\", \"WeeTime_2\",\n                 \"WeeTime_3\", \"WeeTime_4\", \"TirImEx\", \"TirPlIn\", \"TirTime_1\",\n                 \"TirTime_2\", \"TirTime_3\", \"TirTime_4\", \"WhiImIn\", \"WhiPlIn\",\n                 \"WhiTime_1\", \"WhiTime_2\", \"WhiTime_3\", \"WhiTime_4\", \"BlaImIn\",\n                 \"BlaPlIn\", \"BlaTime_1\", \"BlaTime_2\", \"BlaTime_3\", \"BlaTime_4\",\n                 \"OJImIn\", \"OJPlIn\", \"OJTime_1\", \"OJTime_2\", \"OJTime_3\",\n                 \"OJTime_4\", \"NumberIntr\", \"Number\", \"Familiarity\",\n                 \"SeenBefore\", \"WhenTaken\", \"DescribeSt\", \"DemoIntro\",\n                 \"DemoGender\", \"DOB\", \"Age\", \"DemoEducat\", \"Income\", \"Religion\",\n                 \"Race\", \"DebriefInt\", \"OddConfusi\", \"ThinkStudy\", \"MoreEye\",\n                 \"ThoughtsCo\", \"LocationLatitude\", \"LocationLongitude\",\n                 \"LocationAccuracy\", \"X\")\n\n# File 3\nnames(raw3) <- c(\"ResponseID\", \"ResponseSet\", \"Name\", \"ExternalDataReference\",\n                 \"EmailAddress\", \"IPAddress\", \"Status\", \"StartDate\", \"EndDate\",                 \n                 \"Finished\", \"Intrinsic.sum\", \"Intrinsic.weightedAvg\",\n                 \"Intrinsic.weightedStdDev\", \"OrderCon\", \"Cond\", \"Part\",\n                 \"NaAssign2\", \"NaAssign1\", \"CLAssign2\", \"CLAssign1\",\n                 \"CLInstrux\", \"Memorize\", \"InExIntro\", \"CerImEx\", \"CerPlEx\",\n                 \"CerTime_1\", \"CerTime_2\", \"CerTime_3\", \"CerTime_4\", \"DiaImEx\",\n                 \"DiaPlEx\", \"DiaTime_1\", \"DiaTime_2\", \"DiaTime_3\", \"DiaTime_4\",\n                 \"PinImEx\", \"PinPlEx\", \"PinTime_1\", \"PinTime_2\", \"PinTime_3\",\n                 \"PinTime_4\", \"WeeImEx\", \"WeePlEx\", \"WeeTime_1\", \"WeeTime_2\",\n                 \"WeeTime_3\", \"WeeTime_4\", \"TirImEx\", \"TirPlEx\", \"TirTime_1\",\n                 \"TirTime_2\", \"TirTime_3\", \"TirTime_4\", \"WhiImEx\", \"WhiPlEx\",\n                 \"WhiTime_1\", \"WhiTime_2\", \"WhiTime_3\", \"WhiTime_4\", \"BlaImEx\",\n                 \"BlaPlEx\", \"BlaTime_1\", \"BlaTime_2\", \"BlaTime_3\", \"BlaTime_4\",\n                 \"OJImEx\", \"OJPlEx\", \"OJTime_1\", \"OJTime_2\", \"OJTime_3\",\n                 \"OJTime_4\", \"NumberIntr\", \"Number\", \"Familiarity\",\n                 \"SeenBefore\", \"WhenTaken\", \"DescribeSt\", \"DemoIntro\",\n                 \"DemoGender\", \"DOB\", \"Age\", \"DemoEducat\", \"Income\", \"Religion\",\n                 \"Race\", \"DebriefInt\", \"OddConfusi\", \"ThinkStudy\", \"MoreEye\",\n                 \"ThoughtsCo\", \"LocationLatitude\", \"LocationLongitude\",\n                 \"LocationAccuracy\", \"X\")\n```\n\nOne of the data sets (raw1) contains participants in both the inherent and extrinsic conditions, identified by the 'Inherent' variable. The other two data sets contain participants in only one of the two conditions and do not have a variable to indicate which condition. We'll add an 'Inherent' variable to each so that the combined data set will have this information for all participants.\n\n```{r}\nraw2[, \"Inherent\"] <- 2\nraw3[, \"Inherent\"] <- 1\n```\n\nLet's also just add a note for which file each case comes from before we combine.\n```{r}\nraw1[, \"file\"] <- 1\nraw2[, \"file\"] <- 2\nraw3[, \"file\"] <- 3\n```\n\nCombine the data sets.\n```{r}\nraw <- merge(raw1, raw2, all = TRUE)\nraw <- merge(raw, raw3, all = TRUE)\n```\n\n\n## Create a single column for each explanandum\n\nThe data for each explanandum are stored in four different columns, named with 7 characters according to the following convention:\n\n+ first 3 characters: code for explanandum\n+ next 2 characters: meaning of 11 endpoint (Im = Implausible; Pl = Plausible)\n+ last 2 characters: explanation type (In = Inherent; Ex = Extrinsic)\n\nThese should be combined to a single column for each explanandum, with 11 indicating Plausible. Extrinsic/Inherent condition is between subjects and stored in the Cond column, so we do not need to worry about preserving this distinction. Therefore, our final variable for each explanandum will be the sum of the four columns, reverse scoring the sum for cases where OrderCon == 1 (11 is implausible). When we sum, unanswered responses will be coded as 0, so we will set these to NA before reversing. We'll name the final variable with just the 3-letter explanandum code (i.e., the first three characters).\n\nThe function below takes as input the data frame and the three letter code for an explanandum and returns a vector of the scores all participants gave for the explanandum, coded so that 11 always indicated the most plausible and 1 always indicates the least plausible.\n\n```{r}\ncombineRatings <- function(data, explanandum) {\n  data[, explanandum] <- rowSums(data[,c(paste(explanandum, \"ImIn\", sep = \"\"),\n                                         paste(explanandum, \"ImEx\", sep = \"\"),\n                                         paste(explanandum, \"PlIn\", sep = \"\"),\n                                         paste(explanandum, \"PlEx\", sep = \"\"))],\n                                 na.rm = TRUE)\n  data[data[, explanandum] == 0, explanandum] <- NA\n  data[data[, \"OrderCon\"] == 1, explanandum] <- 12 - data[data[\"OrderCon\"] == 1,\n                                                          explanandum]\n  return(data[, explanandum])\n}\n```\n\nNext, we'll create a vector of the explananda codes and iterate through it to create the final, correctly coded set of explanation ratings.\n\n```{r}\nexplananda <- c(\"Cer\", \"Dia\", \"Pin\", \"Wee\", \"Tir\", \"Whi\", \"Bla\", \"OJ\")\n\nfor (i in c(1:length(explananda))) {\n  raw[, explananda[i]] <- combineRatings(raw, explananda[i])\n}\n```\n\n## Reduce data set to a final, usable set of cases\n\nThe final data set should only contain cases that represent:\n\n+ True participants (i.e., not survey tests)\n+ Completed surveys (i.e., not withdrawn participants)\n+ US participants\n+ Participants who have unique IP addresses (i.e., are likely not repeats)\n+ Participants who actually responded to the dependent measures\n\nWe already have columns indicating the first two criteria (`Status` and `Finished`, respectively), so we just need to create columns indicating the last three.\n\n### US IP addresses\n\nFirst, we will use IP addresses to identify participants who completed the survey from the US. (The API key will only work from my IP address; to get an API key, go to http://www.ipinfodb.com/ip_location_api.php).\n\n```{r}\ncurrentIP <- fromJSON(readLines(\"http://api.hostip.info/get_json.php\",\n                                warn=F))$ip\nif (currentIP == \"192.17.199.115\") {\n  key <- \"af85998b5aa454631033c7d9da3798109cf709d0647c499f7ffb422562e05eef\"\n} else if (currentIP == \"192.17.136.184\") {\n  key <- \"740a84d1901cafca76be40dca051c202dac777ed3504ae2714d2eebd70d55186\"\n} else {\n  key <- \"41fcdc1796217c72a78bc254925dcff0b27f28acad726c7e967b11296c856ca8\"\n}\n\n# initialize a vector that will be TRUE if participants' IP addresses are\n# in the US and FALSE otherwise\nUS <- vector(mode = \"logical\", length = with(raw, length(IPAddress)))\n\n# iterate through IP addresses, look up their location, and record whether US\nfor (i in 1:with(raw, length(IPAddress))){\n  scrap <- with(raw, scrape(paste(\"http://api.ipinfodb.com/v3/ip-country/?key=\",\n                                  key, \"&ip=\", IPAddress[i], sep = \"\")))\n  if (length(grep(\"United States\", attributes(scrap[[1]])$headers) > 0)) {\n    US[i] <- TRUE\n  }\n}\n\n# add the vector to the raw data\nraw <- cbind(raw, US)\n```\n\n### Unique IP addresses\n\nNext, we'll reate a variable indicating whether the IP address is a duplicate of an IP address taking the survey at an earlier time. First, covert `StartDate` to a time format. Then, sort the data by `StartDate`. Finally, compare IP addresses.\n\n```{r}\nraw$StartDate <- with(raw, strptime(StartDate, format = \"%Y-%m-%d %H:%M:%S\"))\nraw <- raw[with(raw, order(StartDate)),]\nraw$IPDuplicate <- duplicated(raw$IPAddress)\n```\n\n### Number of questions skipped\n\nNext, we'll create a count of the number of explanations participants chose not to rate so that we can exclude participants who did not rate any explanations.\n\n```{r}\nraw[, \"numNAs\"] <- apply(raw[, explananda], 1, function(z) sum(is.na(z)))\n```\n\n### Counting cases\n\nWe will create counts for the numbers of valid participants (i.e., not previews and not withdrawn/quit), participants exclused for various reasons, and included participants. Keep in mind that participants may meet multiple exclusion criteria (e.g., taking the survey from outside the US and skipping all explanation ratings).\n\n```{r}\n# number of valid cases\ncaseCount <- nrow(raw[with(raw, Status == 0 & Finished == 1),])\n\n# number of non-US cases\nnonUScount <- with(raw[with(raw, Status == 0 & Finished == 1),], \n                   length(US[US == FALSE]))\n\n# number of duplicate IP addresses\ndupIPcount <- with(raw[with(raw, Status == 0 & Finished == 1),],\n                   length(IPDuplicate[IPDuplicate == TRUE]))\n\n# number who skipped all explanation ratings\nskippedAllQsCount <- with(raw[with(raw, Status == 0 & Finished == 1),],\n                          length(numNAs[numNAs == 8]))\n```\n\nFrom `r caseCount` raw cases, `r nonUScount` had non-US IP addresses, `r dupIPcount` took the survey from an IP addresses that completed the survey at an earlier time, and `r skippedAllQsCount` skipped all of the explanation ratings.\n\n### Final data set\n\nFinally, we will create a reduced data set that includes only valid cases that are not excluded for any of the reasons above. \n\n```{r}\nfinal <- raw[with(raw, US == TRUE & IPDuplicate == FALSE & Status == 0\n                  & Finished == 1 & numNAs < 8),]\n```\n\nThis final data set contains `r nrow(final)` cases.\n\n\n## Inter-item correlations and summary score for the explananda\n\nTo test the idea that people will rate inherent explanations as more plausibile, and that this difference will be exagerated under cognitive load, we will create a summary score of participants' plausibility ratings.\n\nBut first, let's check that there is some common variance in participants' ratings across the different explananda by looking at the items' interrelations with one another. \n\n```{r, echo=FALSE, dpi=300, fig.height = 6, fig.cap=\"Interitem correlations and densities for eight explananda\", message = FALSE, warning = FALSE}\nggpairs(final[,explananda], lower = list(continuous = \"density\"))\n```\n\nIt looks like the explanation ratings are *generally* well correlated, so we will create a summary score averaging them for each participant. One participant skipped one explanation, and we will impute this value as the median value for that explanandum before creating an average for that participant.\n\n```{r}\n# create lists of key values \nkey.list <- list(plausibility = c(1,2,3,4,5,6,7,8))\n\n# link items names to key values\nkeys <- make.keys(8, key.list, item.labels = explananda)\nkeys\n\n# create scores\nscores <- scoreItems(keys, final[, explananda], totals = FALSE, \n                     missing = TRUE, impute = \"median\")\n\n# add the plausibility ratings to the data frame\nfinal[,\"plausibility\"] <- scores$scores[,1]\n\n# print some summary stats for the scale\nscores\n```\n\nWe will also compute standardized values for the plausibility scores.\n\n```{r}\nfinal[,\"plausibility.z\"] <- scale(final[,\"plausibility\"])\n```\n\n## Create weighted effect-coded versions of condition contrasts\n\nFor the regression model, we will use weighted effect coded contrasts for the two independent variables. We'll create columns in the data set for these.\n\n```{r}\n# Cognitive load\nloadbalance <- table(final[, \"Cond\"])\nfinal[final[,\"Cond\"] == 2, \"load\"] <- loadbalance[1] / nrow(final)\nfinal[final[,\"Cond\"] == 1, \"load\"] <- -1 * loadbalance[2] / nrow(final)\n\n# Inherent-Extrinsic\ninherentbalance <- table(final[, \"Inherent\"])\nfinal[final[,\"Inherent\"] == 2, \"inex\"] <- inherentbalance[1] / nrow(final)\nfinal[final[,\"Inherent\"] == 1, \"inex\"] <- -1 * inherentbalance[2] / nrow(final)\n\n# Write this final data set to a .csv\nwrite.table(final, \"cogLod.csv\", sep = \",\", )\n```\n\n## Confirmatory Analysis\n\nWe will regress the standardized plausibility ratings on the Inherent-Extrinsic contrast, the Cognitive Load contrast, and their interaction. In this model, the coefficients for the two contrasts can be interpreted as standardized mean differences between the conditions. Since the dependent variable and the independent variables are all centered, the intercept is 0 and can be omitted from the model.\n\n```{r}\nplaus.lm <- lm(plausibility.z ~ inex*load -1, final)\nsummary(plaus.lm)\n```\n\nWe will also look at the raw means for the four conditions.\n\n```{r, cache = FALSE}\nvars <- c(\"inex\", \"load\", \"file\", \"plausibility\")\nmeans <- ddply(final[, vars], .(inex, load), summarize,\n              n = length(plausibility),\n               cilow = t.test(plausibility)$conf.int[1],\n               cihigh = t.test(plausibility)$conf.int[2],\n              plausibility = mean(plausibility))\nmeans[, \"inex\"] <- with(means, factor(inex,\n                                      labels = c(\"Extrinsic\", \"Inherent\")))\nmeans[, \"load\"] <- with(means, factor(load,\n                                      labels = c(\"Low load\", \"High load\")))\n\nprint(means)\n```\n\nFinally, we will plot the means for each group.\n\n```{r, echo=FALSE, dpi=300, fig.height = 6, fig.cap=\"Mean, 95% confidence interval, and probability density for plausibility ratings of explanations by Explanation Type (Extrinsic vs. Inherent) and Cognitive Load (Low vs. High)\", message = FALSE, warning = FALSE}\ndodge <- position_dodge(width = .9)\n\nggplot(final, aes(x = factor(inex, labels = c(\"Extrinsic\", \"Inherent\")),\n                  y = plausibility, ymax = t.test(plausibility)$conf.int[2],\n                  colour = factor(load, labels = c(\"Low\", \"High \")))) + \n  geom_violin(position = dodge) +\n  scale_x_discrete(\"Explanation Type\") +\n  scale_y_continuous(\"Plausibility\", limits=c(1, 11), breaks = c(1:11)) +\n  geom_pointrange(data = means, aes(ymin = cilow, ymax = cihigh),\n                  width = 0.2, position = dodge) +\n  scale_color_manual(values = c(\"#E69F00\", \"#56B4E9\"),\n                     guide = guide_legend(title = \"Cognitive \\nLoad\")) +\n  theme_classic()\n```\n\n",
    "created" : 1452614876255.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3859465458",
    "id" : "7A7D6E28",
    "lastKnownWriteTime" : 1444517810,
    "path" : "~/Box Sync/Research/IH_Inherence Heuristic/CogLoad1/cogLoad/cogLoad.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}
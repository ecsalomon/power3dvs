---
title: 'Data Analysis for: Priming Power with 3 DVs'
author: "Erika Salomon"
date: "January 12, 2016"
output:
  pdf_document:
    fig_caption: yes
---

```{r setup, include=FALSE}
# Load Packages
library(psych)
library(ggplot2)
library(GGally)
library(plyr)
library(reshape)
```

## Summary

This file reports data manipulations and analyses performed on an experiment studying the effects of power primes. Participants recruited via Mechanical Turk completed a power priming manipulation in which they were asked recall and visualize a time when they were high or low in power. After writing a description of their visualization, they completed a series of tasks to assess three dependent variables.

Participants'  **action/inaction intentions** were measured with 7 questions (e.g., "I am feeling energetic"; 1 = *not at all*, 7 = *extremely*; Albarracin, 2009, unpublished). 

Participants' **trust** was measured with two measures. Six items from the World Values Survey asked how much participants trust people belonging to different groups (e.g., "People you meet for the first time"; 1 = *trust completely*, 4 = *do not trust at all*). Participants also completed the trust game (Berg et al., 1995), which asked them how many raffle tickets they would entrust to another person who may or may not return them.

Two measures assessed participants' **perspective taking**. Participants answered seven items from the perspective-taking subscale of the Interpersonal Reactivity Index (Davis, 1980). These items were slightly modified to assess state rather than trait perspective taking motivation (e.g., "Before criticizing somebody, I'd try to imagine how I would feel if I were in their place"; 1 = *does not describe me at all*, 5 = *describes me very well*). Participants also completed 10 items from the Adult Reading the Mind in the Eyes Test-Revised (Baron-Cohen, Wheelwright, Hill, Raste & Plumb, 2001), which asked them to look at images of people's eyes and choose which of four emotions was expressed.

Participants completed measures for each of the dependent variables in a random order. For trust and perspective-taking, the two measures were also randomly ordered.

## Load the raw data

The data were collected using Qualtrics. The first row of the raw data file contains most of the variable names. The second row contains some further variable names and the question wording. Rows three and beyond contain participant data. So we will first load in the two sets of variable names and combine them. Then, we will load in the data.

```{r, cache=FALSE}
filename <- "PR__Priming_Power__3_DVs__Action_PerspectiveTaking_Distrust.csv"

name1 <- names(read.csv(filename, nrow = 1))
name2 <- names(read.csv(filename, nrow = 1, skip = 1))
names <- c(name2[1:22], name1[23:(length(name1))])
raw <- read.csv(filename, header = FALSE, skip = 2, col.names = names,
                stringsAsFactors = FALSE)
```

## Reduce data set to a final, usable set of cases

The final data set should only contain cases that represent:

+ US participants
+ Participants who passed the instructional manipulation check (IMC)

We will identify and count cases that do not meet these criteria. 

```{r}
# how many cases total?
totalCases <- nrow(raw)

# identify surveys from outside the US
nonUScount <- nrow(raw[with(raw, Country != "United States"),])

# identify participants who failed the IMC
failedIMCcount <- nrow(raw[with(raw, IMC != 10),])

# identify participants who meet both exclusion criteria
bothExcludeCount <- nrow(raw[with(raw,IMC != 10 & Country != "United States"),])

# create final data set and count cases
final <- raw[with(raw, IMC == 10 & Country == "United States"),]
finalCases <- nrow(final)
```

From `r totalCases` raw cases, `r nonUScount` had non-US IP addresses and `r failedIMCcount` failed the IMC (`r bothExcludeCount` failed the IMC *and* had a non-US IP), leaving `r finalCases` for analysis.

## Create labels for categorical/ordinal demographic variables

The categorical and ordinal demographic variables (e.g., race, gender) are coded with numbers. We want to add category labels to these. 

```{r}
# ethnicity/race
final$ethnic2 <- factor(final$ethnic2,
                        levels = c(1,2,3,4,5,6),
                        labels = c("African American",
                                   "Asian American",
                                   "European American",
                                   "Latino/Latina",
                                   "Native American",
                                   "Other"))

# gender
final$gender <- factor(final$gender,
                       levels = c(1,2),
                       labels = c("Male", "Female"))

# income 
final$yyour <- factor(final$yyour,
                      levels = c(1,2,3,4,5,6,7,8),
                      labels = c("Under $15,000",
                                 "$15,001 - $25,000",
                                 "$25,000 - $35,000",
                                 "$35,001 - $50,000",
                                 "$50,001 - $75,000",
                                 "$75,001 - $100,000",
                                 "$100,001 - $150,000",
                                 "Over $150,000"))

# education 
final$youred <- factor(final$youred,
                       levels = c(1,2,3,4,5),
                       labels = c("Less than high school",
                                  "High school graduation or equivalent",
                                  "Some college", "College graduation",
                                  "Professional / Post-graduate degree"))
```

## Create condition variables for analyses

Conidition was recorded with a dummy code (0 = Low Power; 1 = High Power). We will convert these to effect codes with a 1 unit difference, weighted by the number of participants randomly assigned to the other condition. Weighted effect codes will produce regression coefficients that represent the mean difference between the groups. 

```{r}
# how many participants were assigned to each condition?
lowN <- nrow(final[final$Cond == 0,])
highN <- nrow(final[final$Cond == 1,])

# create weights
final$effect[final$Cond == 0] <- -highN / finalCases
final$effect[final$Cond == 1] <- lowN / finalCases
```

There were `r lowN` and `r highN` participants in the Low and High Power conditions, respectively.

We will also turn the original dummy code into a factor, which will be useful for plotting and tables.

```{r}
final$Cond <- factor(final$Cond,
                     levels = c(0,1),
                     labels = c("Low Power", "High Power"))
```


## Exploratory data analysis

Before we run our preferred model, we should use exploratory data analysis to examine the distributions of variables and investigate the potential influence of order effects on the dependent variables.

### Descriptive summaries of demographic variables

First, we will look at the demographic composition of our sample.
 
```{r}
# Gender
table(final[,"gender"])

# Age
describe(final[,"age"])

# Race/ethnicity
prop.table(table(final$ethnic2))

# Income
prop.table(table(final[,"yyour"]))

# Education
prop.table(table(final$youred))
```

Overall, the sample looks similar to other Mechanical Turk samples.

### Examine distributions of dependent variables

Next, we will look at distributions of the dependent variables to assess whether there are issues with the way the data were recorded and whether there are obvious problems with the distributions.

#### Individual items

First, we should examine the individual items. Are there issues with how the data were recorded (e.g., impossible values, reverse keyed).

Before we look at the items, we will need to score the items of the Reading the Mind in the Eyes (RME) test.

```{r}
# the correct answers
answers <- c(1, 2, 3, 2, 3, 2, 3, 1, 4, 1)
answers <- answers + 18 # responses were recorded as 19 through 22

# for each item, initialize a score column with 0s, change to 1 if the
# participant got the right answer
for (i in 1:10) {
  colName <- names(final)[68 + i]
  newName <- paste(colName, "score", sep = "")
  final[, newName] <- 0
  final[final[, colName] == answers[i], newName] <- 1
}
```

Now we can look at the items.

```{r}
# Which columns represent items?
actionCols <- c(44:50) # action goals
wvsCols <- c(51:56) # World Values Survey trust
gameCol <- 58 # trust game
iriCols <- c(61:67) # IRI
rmeCols <- c(117:126) # RME
dvCols <- c(actionCols, wvsCols, gameCol, iriCols, rmeCols)

# Create long versions of the data set for each scale, where each item rating 
# for each participant is on a separate line
variable.names <- names(final)
actionDVs <- melt(final, id = "ResponseID",
                  measure.vars = variable.names[c(actionCols)])
wvsDVs <- melt(final, id = "ResponseID",
               measure.vars = variable.names[c(wvsCols)])
iriDVs <- melt(final, id = "ResponseID",
               measure.vars = variable.names[c(iriCols)])
rmeDVs <- melt(final, id = "ResponseID",
               measure.vars = variable.names[c(rmeCols)])
```

We'll look at plots for each set of variables.
\
\
```{r, echo=FALSE, dpi=300, fig.height = 3, message = FALSE, warning = FALSE}
actionBarPlot <- ggplot(actionDVs, aes(x = factor(value))) + 
  geom_bar() +
  facet_wrap(~ variable) +
  xlab("score") +
  ggtitle("Distributions of Raw Responses to Action/Inaction Goal Items")
actionBarPlot
```
\
\
The action/inaction items were recorded as 19 to 26, instead of 1 to 7.
\
\
```{r, echo=FALSE, dpi=300, fig.height = 3, message = FALSE, warning = FALSE}
wvsBarPlot <- ggplot(wvsDVs, aes(x = factor(value))) + 
  geom_bar() +
  facet_wrap(~ variable) +
  xlab("score") + 
  ggtitle("Distributions of Raw Responses to World Values Survey Trust Items")
wvsBarPlot
```
\
\
One of the World Values Survey trust items has a severely skewed distribution. This is unsurprising as it indicates that most people trust their families completely.
\
\
```{r, echo=FALSE, dpi=300, fig.height = 3, message = FALSE, warning = FALSE}
gameHist <- ggplot(final, aes(x = TrustGame_1)) + 
  geom_histogram() +
  xlab("tickets given") + 
  ggtitle("Historgram of Number of Tickets Given Away in Trust Game")
gameHist
```
\
\
There is a good spread of responses across the Trust Game, with an obvious mode around 500.
\
\
```{r, echo=FALSE, dpi=300, fig.height = 3, message = FALSE, warning = FALSE}
iriBarPlot <- ggplot(iriDVs, aes(x = factor(value))) + 
  geom_bar() +
  facet_wrap(~ variable) +
  xlab("score") +
  ggtitle("Distributions of Raw Responses to IRI Items")
iriBarPlot
```
\
\
Like the action/inaction items, the IRI items were recorded beginning at 19 instead of 1.
\
\
```{r, echo=FALSE, dpi=300, fig.height = 3, message = FALSE, warning = FALSE}
rmeBarPlot <- ggplot(rmeDVs, aes(x = factor(value))) + 
  geom_bar() +
  facet_wrap(~ variable) +
  xlab("score") +
  scale_y_continuous(breaks = c(0, 125, 250, 375, 500)) +
  ggtitle("Distributions of Raw Responses to IRI Items")
rmeBarPlot
```
\
\
Overall, people were fairly accurate on the Reading the Mind in Eyes items, though some of items show substantial proportions of people who answered incorrectly.

We will recode the items from the action/inaction goals scale and the IRI perspective-taking scale so that they are scored as 1 to 7 and 1 to 5, respectively.

```{r recode}
# for each item, subtract 18 from the score
final[, c(actionCols, iriCols)] = final[, c(actionCols, iriCols)] - 18
```

### Compute Scale Scores & Cronbach's alphas

Next, we will combine the items into scales and examine their intercorrelations. Some of the items need to be reverse scored before being combined with other items.

```{r reverse score}
# reverse score inaction goal items from action/inaction goals scale
final[, c("AI03nap", "AI05rest", "AI07relax")] <- 8 - final[, c("AI03nap", "AI05rest", "AI07relax")]

# reverse score non-prespective-taking items from IRI
final[, c("IRI01", "IRI04")] <- 6 - final[, c("IRI01", "IRI04")]

# reverse score items on the WVS trust measure so that 4 indicates high trust
final[, wvsCols] <- 5 - final[, wvsCols]
```

```{r cronbach}
# create lists of key values identifying which items will be included in which
# scales
key.list <- list(action = c(1:7), 
                 wvs    = c(8:13), 
                 game   = c(14),
                 iri    = c(15:21),
                 rme    = c(22:31))

# link items names to key values
keys <- make.keys(31, key.list, item.labels=c(colnames(final)[dvCols]))

# create scores
scores <- scoreItems(keys,
                     final[, dvCols],
                     totals = FALSE,
                     missing = TRUE,
                     impute = "median")

# add the scores to the data set
final <- cbind(final, scores$scores)

### Create standardized scale scores
stdScores <- scale(scores$scores)
colnames(stdScores) <- paste(colnames(stdScores), ".z", sep = "")
final <- cbind(final, stdScores)

print(scores, short = FALSE)
```

It looks like the two trust measures are weakly positively correlated, and the two perspective-taking measures are uncorrelated. For this reason, we will analyze these scales separately.

### Examine demographics by condition

Let's take a look at the demographic characteristics of each condition separately.

```{r condition demo}
ddply(final, .(Cond), summarize,
      men = length(ResponseID[gender == "Male"]) / length(ResponseID),
      women = length(ResponseID[gender == "Female"]) / length(ResponseID),
      mean.age = mean(age), 
      perc.white = length(ResponseID[ethnic2 == "European American"]) / length(ResponseID))
```


### Examine order effects

Let's take a look at the demographic characteristics of each condition separately.

```{r condition demo}
ddply(final, .(Cond), summarize,
      men = length(ResponseID[gender == "Male"]) / length(ResponseID),
      women = length(ResponseID[gender == "Female"]) / length(ResponseID),
      mean.age = mean(age), 
      perc.white = length(ResponseID[ethnic2 == "European American"]) / length(ResponseID))
```

## Confirmatory analyses

Now, let's look a